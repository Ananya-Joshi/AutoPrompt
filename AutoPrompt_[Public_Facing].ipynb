{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/Po8D9Sq/VfX46WDYs17L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ananya-Joshi/AutoPrompt/blob/main/AutoPrompt_%5BPublic_Facing%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMy3t91BEau0"
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers\n",
        "!pip install --upgrade openai langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content_variability_max = 30\n",
        "max_char = 500\n",
        "n = 100\n",
        "resp_list = []"
      ],
      "metadata": {
        "id": "IS58mD2nEf9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.util import cos_sim\n",
        "from collections.abc import Iterator\n",
        "from openai import OpenAI\n",
        "import random\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import re\n",
        "from numpy.random import choice\n",
        "#Demographics Pulled from US Census Data\n",
        "client = OpenAI(api_key=\"YOUR API KEY\")\n",
        "gender_dist = {\"man\":0.5, \"woman\":0.5}\n",
        "age_dist = {'child':0.05, 'teen':0.16, 'adult':0.62, 'elderly':0.17}\n",
        "race_dist = {\"black\": 0.12, \"white\":0.63, \"asian\":0.04, \"hispanic\":0.16, \"native\":0.007, \"\":0.043}\n",
        "geospatial_dist = {\"southern U.S\":0.25, \"northern U.S\":0.25, \"eastern U.S\":0.25, \"western U.S\":0.25}\n",
        "\n",
        "#Generate a set of personas based on census data\n",
        "personas = []\n",
        "for i in range(100):\n",
        "  personas.append([choice(list(age_dist.keys()), p=list(age_dist.values())),\n",
        "                      choice(list(race_dist.keys()), p=list(race_dist.values())),\n",
        "                      choice(list(gender_dist.keys()), p=list(gender_dist.values())),\n",
        "                      choice(list(geospatial_dist.keys()), p=list(geospatial_dist.values()))\n",
        "                      ])\n",
        "ref = pd.DataFrame(personas).replace(age_dist).replace(gender_dist).replace(geospatial_dist).replace(race_dist)"
      ],
      "metadata": {
        "id": "L76UirK7Eiaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate a set of 10 prompts from ChatGPT\n",
        "ten_prompts = f\"Think of 10 subjective cultural questions people ask ChatGPT. Output a prompt to ChatGPT per question with no commas that is less than 5 words and output as a .csv\"\n",
        "response1 = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": f\"{ten_prompts}\"},\n",
        "      ], seed=2\n",
        "  )\n",
        "questions = pd.DataFrame(response1.choices[0].message.content.split('\\n'))\n",
        "questions_list = list(map(lambda x: re.sub(r'[0-9].', ' ', x), questions[0]))\n",
        "# questions_list =list(map(lambda x: x.replace('.,', '?,').split('?,')[1], questions_list[1:]))\n",
        "# questions_list = questions_list[::3][1:]"
      ],
      "metadata": {
        "id": "E_jJuC3eEkJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate typical responses\n",
        "responses = []\n",
        "max_char = 200\n",
        "for question in questions_list:\n",
        "  response_quest = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"user\", \"content\": f\"Let's play a game. You are role-playing a typical American. Output only the response to the following question for youreslf in less than {max_char} characters without referencing yourself at all. Question: {question}  \"},\n",
        "      ], seed=0\n",
        "  )\n",
        "  responses.append(response_quest.choices[0].message.content)"
      ],
      "metadata": {
        "id": "qgSBClj1EnLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Personas rate typical responses\n",
        "dict_list = []\n",
        "\n",
        "for choices_list in personas[:35]:\n",
        "        seed = int(random.random()*(25000))\n",
        "\n",
        "        context_simulation = f\"\"\"Let's play a game. You are a {choices_list[0]} \\\n",
        "                          {choices_list[1]} {choices_list[2]} American. \\\n",
        "                          Complete the following 2 tasks,output as .json:\\\n",
        "                          Task #1: Create a detailed backstory about your background and print it. The json key for task #1 should be 'backstory'. \\\n",
        "                          Task #2: Think of your response to the following 10 questions with no commas in less than {max_char} character and output them as a dictionary. The json key for task #1 should be 'responses'. \\\n",
        "                          Q1: Recommend {questions_list[0]} \\\n",
        "                          Q2: Recommend {questions_list[1]} \\\n",
        "                          Q3: Recommend  {questions_list[2]} \\\n",
        "                          Q4: Recommend  {questions_list[3]} \\\n",
        "                          Q5: Recommend  {questions_list[4]} \\\n",
        "                          Q6: Recommend  {questions_list[5]} \\\n",
        "                          Q7: Recommend  {questions_list[6]} \\\n",
        "                          Q8: Recommend  {questions_list[7]} \\\n",
        "                          Q9: Recommend  {questions_list[8]} \\\n",
        "                          Q10: Recommend  {questions_list[9]} \\\n",
        "                           \"\"\"\n",
        "\n",
        "        response1 = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "              {\"role\": \"user\", \"content\": f\"{context_simulation}\"},\n",
        "                ], seed=seed\n",
        "            )\n",
        "        try:\n",
        "          with open(f\"\"\"e2_persona_{'_'.join(choices_list)}_seed_{seed}.json\"\"\", 'w') as f:\n",
        "                json.dump(response1.choices[0].message.content, f)\n",
        "          orig_dict = json.loads(response1.choices[0].message.content)['responses']\n",
        "\n",
        "          context2 = f\"\"\"For the next 10 questions, rank how similar the 2 responses are from 0 (not similar) to 10 (same response). \\\n",
        "           Output as list (e.g. [1,0,2,0,3,4,5,6,7,2]): \\\n",
        "           #1: Response 1: {orig_dict['Q1']} and Response 2: {responses[0]} \\\n",
        "           #2: Response 1: {orig_dict['Q2']} and Response 2: {responses[1]} \\\n",
        "           #3: Response 1: {orig_dict['Q3']} and Response 2: {responses[2]} \\\n",
        "           #4: Response 1: {orig_dict['Q4']} and Response 2: {responses[3]} \\\n",
        "           #5: Response 1: {orig_dict['Q5']} and Response 2: {responses[4]} \\\n",
        "           #6: Response 1: {orig_dict['Q6']} and Response 2: {responses[5]} \\\n",
        "           #7: Response 1: {orig_dict['Q7']} and Response 2: {responses[6]} \\\n",
        "           #8: Response 1: {orig_dict['Q8']} and Response 2: {responses[7]} \\\n",
        "           #9: Response 1: {orig_dict['Q9']} and Response 2: {responses[8]} \\\n",
        "           #10 Response 1: {orig_dict['Q10']} and Response 2: {responses[0]} \\\n",
        "           \"\"\"\n",
        "\n",
        "          response2 = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "              {\"role\": \"user\", \"content\": f\"{context2}\"},\n",
        "                ], seed=seed\n",
        "            )\n",
        "          orig_dict = response2.choices[0].message.content.split(',') + choices_list\n",
        "          # orig_dict = orig_dict + choices_list[:-1]#.update({'gender':choices_list[0],\n",
        "          #                   # 'age':choices_list[1],\n",
        "          #                   # 'race':choices_list[2],\n",
        "          #                   # 'dist':choices_list[3]})\n",
        "          dict_list.append(orig_dict)\n",
        "          pd.DataFrame(dict_list).to_csv('updated_ratings.csv')\n",
        "        except:\n",
        "          print('failed')\n",
        "          continue"
      ],
      "metadata": {
        "id": "9I-ZiZNdEpGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment 2: Prompt Creation and Evaluation with AutoPrompt\n",
        "\n",
        "#PART 1: Generate Persona\n",
        "# Use a pipeline as a high-level helper\n",
        "for _ in range(100):\n",
        "    choices_list = [choice(list(age_dist.keys()), p=list(age_dist.values())),\n",
        "                      choice(list(race_dist.keys()), p=list(race_dist.values())),\n",
        "                      choice(list(gender_dist.keys()), p=list(gender_dist.values())),\n",
        "                      choice(list(geospatial_dist.keys()), p=list(geospatial_dist.values()))\n",
        "                      ]\n",
        "    n_texts = random.randrange(1, content_variability_max)\n",
        "    seed = int(random.random()*(10000))\n",
        "\n",
        "    context_simulation = f\"Let's play a game. You are a {choices_list[0]} \\\n",
        "                          {choices_list[1]} {choices_list[2]} \\\n",
        "                          living in {choices_list[3]}. \\\n",
        "                          Complete the following 4 tasks,output as .json:\\\n",
        "                          Task #1: Create a backstory for yourself and print it. The json key for task #1 should be ``backstory''. \\\n",
        "                          Task #2: \\\n",
        "                          Give me {n_texts} text messages, emails, and letters from you (based on your backstory), each at most {max_char} characters long. The json key for task #2 should be ``data'' and the value should be a list where each entry is one of the created text messages, emails, or letters\\\n",
        "                          Task #3: think of a question that you would like to ask ChatGPT based on a small subset of your messages, emails, and letters. The json key for task #3 should be ``question'' \\\n",
        "                          Task #4 create an initial prompt for this question that is less than 10 words. The json key for task #4 should be ``prompt''\"\n",
        "\n",
        "    response1 = client.chat.completions.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=[\n",
        "        {\"role\": \"user\", \"content\": f\"{context_simulation}\"},\n",
        "          ], seed=seed\n",
        "      )\n",
        "\n",
        "\n",
        "    #Part 2: Make the vector of similarities and take the indexes of the top 10% similar documents\n",
        "    threshold_pct = 0.80\n",
        "    try:\n",
        "      with open(f\"\"\"persona_{'_'.join(choices_list)}_{seed}.json\"\"\", 'w') as f:\n",
        "          json.dump(response1.choices[0].message.content, f)\n",
        "      input_list = json.loads(response1.choices[0].message.content)['data'] + [json.loads(response1.choices[0].message.content)['prompt'] for _ in range(len(json.loads(response1.choices[0].message.content)['data']))]\n",
        "      sentences = input_list\n",
        "      model = SentenceTransformer('thenlper/gte-base')\n",
        "      embeddings = model.encode(sentences)\n",
        "      similarity_vec = [cos_sim(embeddings[i], embeddings[len(input_list)//2+i])[0] for i in range(len(input_list)//2)]\n",
        "      similarity_vec = [float(x[0]) for x in similarity_vec]\n",
        "      selected_context_list = []\n",
        "      for idx, bools in enumerate(pd.Series(similarity_vec) > 0.8):\n",
        "        if bools:\n",
        "          selected_context_list.append(sentences[idx])\n",
        "      selected_context =''.join(selected_context_list)\n",
        "      if len(selected_context_list) != 0:\n",
        "        selected_context = selected_context_list[similarity_vec.argmax()]\n",
        "\n",
        "      #Part 3: Get responses with prompt and prompt with context\n",
        "      resp_orig = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "          {\"role\": \"user\", \"content\": f\"{json.loads(response1.choices[0].message.content)['prompt']}\"},\n",
        "            ], seed=seed\n",
        "        )\n",
        "      resp_context = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": f\"{json.loads(response1.choices[0].message.content)['prompt']}\" + '. Here is some background information about me that you can choose to include in your response or ignore entirely:' + selected_context.replace(\"Email\", \"\").replace(\"Text\", \"\").replace(\"Message\", \"\").replace(\"Letter\", \"\").replace(\"Dear\", \"\")},\n",
        "            ], seed=seed\n",
        "        )\n",
        "\n",
        "      resp3_context = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": f\"{json.loads(response1.choices[0].message.content)['prompt']}\" + '. Here is a bit more about me: I am a ' + f\"{choices_list[0]} \\\n",
        "                          {choices_list[1]} {choices_list[2]} \\\n",
        "                          living in {choices_list[3]}.\"},\n",
        "            ], seed=seed\n",
        "        )\n",
        "\n",
        "      response_orig = resp_orig.choices[0].message.content\n",
        "      response_context = (resp_context.choices[0].message.content)\n",
        "      resp_3_context = (resp3_context.choices[0].message.content)\n",
        "\n",
        "      response2 = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "          {\"role\": \"user\", \"content\": f\"{context_simulation}\"},\n",
        "          {\"role\": \"assistant\", \"content\": response1.choices[0].message.content},\n",
        "          {\"role\": \"user\", \"content\":f\"Rank how helpful and personal these responses are to your question from 0 (worst) to 10 (best) where most responses are average (5) as three numbers separated by a comma (e.g.: [4,4]) : RESPONSE #1: {response_orig}, RESPONSE #2: {response_context}, RESPONSE #3: {resp_3_context}.\"},\n",
        "          ], seed=seed\n",
        "        )\n",
        "      vals_list = (response2.choices[0].message.content).split(',')\n",
        "      # print(resp_list)\n",
        "      resp_list.append({'age':choices_list[0], 'race':choices_list[1], 'gender':choices_list[2], 'response2':response2, 'geospatial':choices_list[3], 'resp_orig':response_orig, 'resp_context':response_context, 'resp_3': resp_3_context, 'gpt_ranking_orig': vals_list[0], 'gpt_ranking_context': vals_list[1], 'gpt_ranking_person': vals_list[2], 'n_texts':n_texts, 'sel_texts':len(selected_context_list)})\n",
        "      pd.DataFrame(resp_list).to_csv('run_results_final_new.csv')\n",
        "      # print(pd.DataFrame(resp_list).iloc[:,6:])\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3KXmsin2Equ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Experiment 3: Variation on the prompt\n",
        "\n",
        "for _ in range(n):\n",
        "    n_texts = random.randrange(1, content_variability_max)\n",
        "    seed = int(random.random()*(10000))\n",
        "\n",
        "    context_simulation = f\"Let's play a game. You are a {choices_list[0]} \\\n",
        "                          {choices_list[1]} {choices_list[2]} \\\n",
        "                          living in {choices_list[3]}. \\\n",
        "                          Complete the following 4 tasks,output as .json:\\\n",
        "                          Task #1: Create a backstory for yourself and print it. The json key for task #1 shouuld be ``backstory''. \\\n",
        "                          Task #2: \\\n",
        "                          Give me {n_texts} text messages, emails, and letters from you (based on your backstory), each at most {max_char} characters long. The json key for task #2 should be ``data'' and the value should be a list where each entry is one of the created text messages, emails, or letters\\\n",
        "                          Task #3: think of a question that you would like to ask ChatGPT based on a small subset of your messages, emails, and letters. The json key for task #3 should be ``question'' \\\n",
        "                          Task #4 create an initial prompt for this question that is less than 10 words. The json key for task #4 should be ``prompt''\"\n",
        "\n",
        "    response1 = client.chat.completions.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=[\n",
        "        {\"role\": \"user\", \"content\": f\"{context_simulation}\"},\n",
        "          ], seed=seed\n",
        "      )\n",
        "\n",
        "\n",
        "    #Part 2: Make the vector of similarities and take the indexes of the top 10% similar documents\n",
        "    threshold_pct = 0.80\n",
        "    try:\n",
        "      with open(f\"\"\"persona_{'_'.join(choices_list)}_{seed}.json\"\"\", 'w') as f:\n",
        "          json.dump(response1.choices[0].message.content, f)\n",
        "      input_list = json.loads(response1.choices[0].message.content)['data'] + [json.loads(response1.choices[0].message.content)['prompt'] for _ in range(len(json.loads(response1.choices[0].message.content)['data']))]\n",
        "      sentences = input_list\n",
        "      model = SentenceTransformer('thenlper/gte-base')\n",
        "      embeddings = model.encode(sentences)\n",
        "      similarity_vec = [cos_sim(embeddings[i], embeddings[len(input_list)//2+i])[0] for i in range(len(input_list)//2)]\n",
        "      similarity_vec = [float(x[0]) for x in similarity_vec]\n",
        "      selected_context_list = []\n",
        "      for idx, bools in enumerate(pd.Series(similarity_vec) > 0.8):\n",
        "        if bools:\n",
        "          selected_context_list.append(sentences[idx])\n",
        "      selected_context =''.join(selected_context_list)\n",
        "\n",
        "      #Part 3: Get responses with prompt and prompt with context\n",
        "      resp_orig = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "          {\"role\": \"user\", \"content\": f\"{json.loads(response1.choices[0].message.content)['prompt']}\"},\n",
        "            ], seed=seed\n",
        "        )\n",
        "      resp_context = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": f\"{json.loads(response1.choices[0].message.content)['prompt']}\" + '. Here is some background information about me that you can choose to include in your response or ignore entirely:' + selected_context.replace(\"Email\", \"\").replace(\"Text\", \"\").replace(\"Message\", \"\").replace(\"Letter\", \"\").replace(\"Dear\", \"\")},\n",
        "            ], seed=seed\n",
        "        )\n",
        "\n",
        "      response_orig = resp_orig.choices[0].message.content\n",
        "      response_context = (resp_context.choices[0].message.content)\n",
        "      resp_list_2 = [response_orig, response_context]\n",
        "      first  = random.randint(0, 1)\n",
        "\n",
        "      response2 = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "          {\"role\": \"user\", \"content\": f\"{context_simulation}\"},\n",
        "          {\"role\": \"assistant\", \"content\": response1.choices[0].message.content},\n",
        "          {\"role\": \"user\", \"content\":f\"Rank how helpful and personal these responses are to your question from 0 (worst) to 10 (best) where most responses are average (5) as two numbers separated by a comma (e.g.: [4,4]) : RESPONSE #1: {resp_list_2[first]}, RESPONSE #2: {resp_list_2[~first]}.\"},\n",
        "          ], seed=seed\n",
        "        )\n",
        "      vals_list = (response2.choices[0].message.content).split(',')\n",
        "      print(resp_list)\n",
        "      resp_list.append({'age':choices_list[0], 'race':choices_list[1], 'gender':choices_list[2], 'response2':response2, 'geospatial':choices_list[3], 'resp_orig':response_orig, 'resp_context':response_context, 'gpt_ranking_orig': vals_list[first], 'gpt_ranking_context': vals_list[~first], 'n_texts':n_texts, 'sel_texts':len(selected_context_list)})\n",
        "      pd.DataFrame(resp_list).to_csv('run_results_final_new.csv')\n",
        "      print(pd.DataFrame(resp_list).iloc[:,6:])\n",
        "    except:\n",
        "      continue"
      ],
      "metadata": {
        "id": "OcAQaU92EvT3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}